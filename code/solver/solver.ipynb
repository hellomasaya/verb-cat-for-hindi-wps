{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba28b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_root_dict():\n",
    "    all_vc_data = pd.read_csv('../data/data-for-ml-models/word-level-info-and-verb-category-data.csv', delimiter='\\t')\n",
    "    return dict(zip(all_vc_data[\"Token\"], all_vc_data[\"Root\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58009410",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems=[]\n",
    "equations=[]\n",
    "for fold in range(0,5):\n",
    "    test_verbs_set = pd.read_csv('../data/data-for-ml-models/test_samples-fold{}_2.csv'.format(fold), delimiter='\\t')\n",
    "    test_verbs_set = test_verbs_set.drop_duplicates(subset=['Problem'])\n",
    "    test = list(test_verbs_set['Problem'])\n",
    "    data = pd.read_csv('../data/data-for-ml-models/word-level-info-and-verb-category-data.csv', delimiter='\\t')\n",
    "    data = data.drop_duplicates(subset=['Problem'])\n",
    "    data = data[data['Problem'].isin(test)]\n",
    "    eq = list(data['Equation'])\n",
    "    problems += test\n",
    "    equations += eq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3724e253",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = {}    \n",
    "for p, e in zip(problems, equations):\n",
    "    dict_[p]=e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9993668",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = dict_.keys()\n",
    "equations = dict_.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05f033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_root_dict = get_token_root_dict()\n",
    "token_root_dict['₹']='₹'\n",
    "token_root_dict['आँवले']='आँवले'\n",
    "token_root_dict['बॉट']='बाँट'\n",
    "token_root_dict['लाईन']='लाईन'\n",
    "token_root_dict['भेड़']='भेड़'\n",
    "token_root_dict['रूमाल']='रूमाल'\n",
    "token_root_dict['ढाणी']='ढाणी'\n",
    "token_root_dict['जूस']='जूस'\n",
    "token_root_dict['बालक-बालिकाएँ']='बालक'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cdce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from isc_tokenizer import Tokenizer\n",
    "from isc_tagger import Tagger\n",
    "from isc_parser import Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f71cad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a90df34",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = Tokenizer(lang='hin', split_sen=True)\n",
    "tagger = Tagger(lang='hin')\n",
    "parser = Parser(lang='hin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55abd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import *\n",
    "X, y, z = symbols('X y z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431bef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# problems = list(data['Problem'])\n",
    "# equations = list(data['Equation'] )\n",
    "answers = []\n",
    "sentences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb40066",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for eq, sent in zip(equations, problems):\n",
    "    try:\n",
    "        sympy_eq = sympify(\"Eq(\" + eq.replace(\"=\", \",\") + \")\")\n",
    "        answer = solve(sympy_eq)\n",
    "        sent = sent.replace('की.ग्रा.', 'किलोग्राम')\n",
    "        sentences.append(sent)\n",
    "        answers.append(answer[0])\n",
    "    except:\n",
    "        print(\"Time based:\", idx, eq)\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4047baf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE\n",
    "source = []\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    source.insert(i, (sentences[i], answers[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b30a23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_money(money):\n",
    "    if money in [\"पैसे\" ,\"पैसा\" ,\"रुपये\" , \"कीमत\", \"क़ीमत\", \"लागत\", \"रुपया\", \"मूल्य\"]:\n",
    "        return \"₹\"\n",
    "    return money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e53ebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "def kartafunc(sent, transferp, transfern, states, sentence_idx):\n",
    "    karta = 0\n",
    "    karma = 0\n",
    "    recepient = 0\n",
    "    transfer_type = '0'\n",
    "    backup_transfer_type = '0'\n",
    "    tagged_sent = tagger.tag(sent)\n",
    "    for words in range(len(tagged_sent) - 1):\n",
    "        current_word = tagged_sent[words][0]\n",
    "        current_tag = tagged_sent[words][1]\n",
    "        next_word = tagged_sent[words + 1][0]\n",
    "        next_tag = tagged_sent[words + 1][1]\n",
    "        # gets subject and object of sentence by identifying case markers\n",
    "        if current_tag == 'NNP' or current_tag == 'NNPC':\n",
    "            if next_word == 'ने' and karta == 0:\n",
    "                karta = current_word\n",
    "            elif next_word == 'को':\n",
    "                recepient = current_word\n",
    "                backup_transfer_type = 't+'\n",
    "            elif next_word == 'से':\n",
    "                recepient = current_word\n",
    "                backup_transfer_type = 't-'\n",
    "        if current_tag == 'QC':\n",
    "            if next_tag == 'JJ':\n",
    "                if tagged_sent[words + 2][1] == 'NN' or tagged_sent[words + 2][1] == 'NNP' or tagged_sent[words + 2][1] == 'NNS' or tagged_sent[words + 2][1] == 'NNPC':\n",
    "                    karma = next_word + \" \" + tagged_sent[words + 2][0]\n",
    "            elif next_tag == 'NN' or next_tag == 'NNP' or next_tag == 'NNPC' or next_tag == 'NNS':\n",
    "                karma = next_word\n",
    "\n",
    "        # in case case markers are used as morphemes\n",
    "        elif current_tag == 'PRP':\n",
    "            if len(states)> sentence_idx and states[sentence_idx][0] not in ['', 0, '0']:\n",
    "                current_word = states[sentence_idx][0]\n",
    "            \n",
    "            if 'ने' in current_word or 'वह' in current_word:\n",
    "                karta = current_word\n",
    "            elif 'को' in current_word or 'उसे' in current_word:\n",
    "                recepient = current_word\n",
    "                backup_transfer_type = 't+'\n",
    "            elif 'से' in current_word:\n",
    "                recepient = current_word\n",
    "                backup_transfer_type = 't-'\n",
    "                \n",
    "\n",
    "        elif current_tag == 'VM':\n",
    "            if current_word in transferp:\n",
    "                transfer_type = 't+'\n",
    "            elif current_word in transfern:\n",
    "                transfer_type = 't-'\n",
    "\n",
    "    karma = check_money(karma)\n",
    "    list_karakas = list()\n",
    "    if karta == karma or karta == recepient or karma == recepient:\n",
    "        return [0, 0, 0, '0']\n",
    "    list_karakas.append(karta)\n",
    "    list_karakas.append(karma)\n",
    "    list_karakas.append(recepient)\n",
    "    list_karakas.append(transfer_type)\n",
    "    return list_karakas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51265587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python2\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "def update_state(karta, karma, verb_type, value, sampradaan, all_but_last_states):\n",
    "    valid_states_idx = []\n",
    "    valid_states_sampradaan_idx = []\n",
    "    is_karta_present = False\n",
    "    is_karma_present_1 = False\n",
    "    is_karma_present_2 = False\n",
    "    is_sampradaan_present = False\n",
    "    state_idx_where_karta = 0\n",
    "    valid_state_idx_where_karma_1 = 0\n",
    "    valid_state_idx_where_karma_2 = 0\n",
    "    state_idx_where_sampradaan = 0\n",
    "\n",
    "    for state in all_but_last_states:\n",
    "        if state[0].strip() == karta:\n",
    "            is_karta_present = True\n",
    "            valid_states_idx.append(int(state_idx_where_karta))\n",
    "        if state[0].strip() == sampradaan:\n",
    "            is_sampradaan_present = True\n",
    "            valid_states_sampradaan_idx.append(int(state_idx_where_sampradaan))\n",
    "        state_idx_where_karta += 1\n",
    "        state_idx_where_sampradaan += 1\n",
    "\n",
    "    if is_karta_present:\n",
    "        for state_idx in valid_states_idx:\n",
    "            if all_but_last_states[state_idx][2].strip() == karma:\n",
    "                is_karma_present_1 = True\n",
    "                break\n",
    "            valid_state_idx_where_karma_1 += 1\n",
    "    if is_sampradaan_present:\n",
    "        for state_idx in valid_states_sampradaan_idx:\n",
    "            if all_but_last_states[state_idx][2].strip() == karma:\n",
    "                is_karma_present_2 = True\n",
    "                break\n",
    "            valid_state_idx_where_karma_2 += 1\n",
    "\n",
    "\n",
    "    if verb_type == 't-':\n",
    "        if is_karta_present and is_karma_present_1 and is_karma_present_2 and is_sampradaan_present:\n",
    "            value_karta = float(all_but_last_states[valid_states_idx[valid_state_idx_where_karma_1]][1])\n",
    "            value_sampradaan = float(all_but_last_states[valid_states_sampradaan_idx[valid_state_idx_where_karma_2]][1])\n",
    "            all_but_last_states[valid_states_sampradaan_idx[valid_state_idx_where_karma_2]] = [\n",
    "                sampradaan, value_sampradaan + float(value), karma]\n",
    "        elif is_karta_present and is_karma_present_1:\n",
    "            value_karta = float(all_but_last_states[valid_states_idx[valid_state_idx_where_karma_1]][1])\n",
    "            all_but_last_states[valid_states_idx[valid_state_idx_where_karma_1]] = [\n",
    "                karta, value_karta - float(value), karma]\n",
    "            all_but_last_states.append([sampradaan, float(value), karma])\n",
    "        elif is_karma_present_2 and is_sampradaan_present:\n",
    "            value_sampradaan = float(all_but_last_states[valid_states_sampradaan_idx[valid_state_idx_where_karma_2]][1])\n",
    "            all_but_last_states[valid_states_sampradaan_idx[valid_state_idx_where_karma_2]] = [\n",
    "                sampradaan, value_sampradaan + float(value), karma]\n",
    "            all_but_last_states.append([karta, -1 * float(value), karma])\n",
    "        else:\n",
    "            all_but_last_states.append([karta, -1*float(value), karma])\n",
    "            all_but_last_states.append([sampradaan, float(value), karma])\n",
    "\n",
    "    if verb_type == 't+':\n",
    "        if is_karta_present and is_karma_present_1 and is_karma_present_2 and is_sampradaan_present:\n",
    "            value_karta = float(all_but_last_states[valid_states_idx[valid_state_idx_where_karma_1]][1])\n",
    "            value_sampradaan = float(all_but_last_states[valid_states_sampradaan_idx[valid_state_idx_where_karma_2]][1])\n",
    "            all_but_last_states[valid_states_idx[valid_state_idx_where_karma_1]] = [\n",
    "                karta, value_karta + float(value), karma]\n",
    "            all_but_last_states[valid_states_sampradaan_idx[valid_state_idx_where_karma_2]] = [\n",
    "                sampradaan, value_sampradaan - float(value), karma]\n",
    "        elif is_karta_present and is_karma_present_1:\n",
    "            value_karta = float(all_but_last_states[valid_states_idx[valid_state_idx_where_karma_1]][1])\n",
    "            all_but_last_states[valid_states_idx[valid_state_idx_where_karma_1]] = [\n",
    "                karta, value_karta + float(value), karma]\n",
    "            all_but_last_states.append([sampradaan, -1 * float(value), karma])\n",
    "        elif is_karma_present_2 and is_sampradaan_present:\n",
    "            value_sampradaan = float(all_but_last_states[valid_states_sampradaan_idx[valid_state_idx_where_karma_2]][1])\n",
    "            all_but_last_states[valid_states_sampradaan_idx[valid_state_idx_where_karma_2]] = [\n",
    "                sampradaan, value_sampradaan - float(value), karma]\n",
    "            all_but_last_states.append([karta, float(value), karma])\n",
    "        else:\n",
    "            all_but_last_states.append([karta, float(value), karma])\n",
    "            all_but_last_states.append([sampradaan, -1*float(value), karma])\n",
    "\n",
    "    return all_but_last_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7761d52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalsent(sent, all_states, is_transfer, change_default_op):\n",
    "    '''\n",
    "    FINDING STATE CORRESPONDING TO QUESTION AND GIVING ANSWER\n",
    "    '''\n",
    "    container = []\n",
    "    positive = ['कुल', 'मिलकर', 'मिलाकर', 'अखंडित']\n",
    "    negative = ['पहले', 'पेहले', 'ज़्यादा', 'ज्यादा', 'तुलना', \n",
    "                'कम', \"मुकाबले\", 'चाहिए',  'अधिक', 'अतिरिक्त', 'शुरुआत', 'शुरू', 'पिछले']\n",
    "    tagged_sent = tagger.tag(sent)\n",
    "    found_container = \"*\"\n",
    "    found_entity = \"*\"\n",
    "    got_adj = \"\"\n",
    "    qf_flag = 0\n",
    "    found_positive_verb = False\n",
    "    if is_transfer:  # there is a transfer occuring\n",
    "        for index in range(0, len(tagged_sent) - 1): # avoids question mark\n",
    "            current_word = tagged_sent[index][0].strip()\n",
    "            current_tag = tagged_sent[index][1]\n",
    "            next_word = tagged_sent[index + 1][0].strip()\n",
    "            next_tag = tagged_sent[index + 1][1]\n",
    "            if current_tag == 'NNP' or current_tag == 'NNPC' or current_tag == 'PRP':\n",
    "                container.append(current_word)\n",
    "            if current_tag == 'JJ':\n",
    "                if next_tag == 'NN' or next_tag == 'NNP' or next_tag == 'NNS' or next_tag == 'NNPC':\n",
    "                    if qf_flag == 1: # LOGIC WORKS ONLY WHEN QUANTITY COMES BEFORE ENTITY\n",
    "                        found_entity = current_word + \" \" + token_root_dict[next_word.strip()]\n",
    "                        break\n",
    "            # NNS not present in Hindi\n",
    "            if current_tag == 'NN' or current_tag == 'NNP' or current_tag == 'NNS' or current_tag == 'NNPC':\n",
    "                if qf_flag == 1: # LOGIC WORKS ONLY WHEN QUANTITY COMES BEFORE ENTITY\n",
    "                    found_entity = token_root_dict[current_word.strip()]\n",
    "                    break\n",
    "            elif current_tag == 'QF':\n",
    "                qf_flag = 1\n",
    "                # CONTAINER IS THE LAST PROPER NOUN AFTER QUANTITY\n",
    "                found_container = container[len(container) - 1].strip()\n",
    "        for state in all_states:\n",
    "            # have to make it container specific\n",
    "            state[0] = state[0].strip()\n",
    "            state[2] = state[2].strip()\n",
    "            if state[0].endswith(found_container) and state[2].endswith(found_entity):\n",
    "                return float(state[1])\n",
    "        \n",
    "        # ADDING ALL QUANTITIES - kul kitne, kul milakar\n",
    "        sum = 0\n",
    "        for state in all_states:\n",
    "            state[2] = state[2].strip()\n",
    "            if state[2].endswith(found_entity) or state[2].startswith(found_entity):\n",
    "                sum = sum + abs(float(state[1]))\n",
    "        return sum\n",
    "    else:\n",
    "        # FINALISE OPERATION + or -\n",
    "        # taking + to be default op\n",
    "        operation = '+'\n",
    "        if change_default_op:\n",
    "            operation = '-'\n",
    "        for words in tagged_sent:\n",
    "            # if I havent already found out negative\n",
    "            if change_default_op is False and found_positive_verb is False:\n",
    "                for check in positive:\n",
    "                    if words[0] == check:\n",
    "                        operation = '+'\n",
    "                        found_positive_verb = True\n",
    "                        break\n",
    "            # If I havent already found out positive\n",
    "            if found_positive_verb is False:\n",
    "                for check in negative:\n",
    "                    if words[0] == check:\n",
    "                        operation = '-'\n",
    "                        break\n",
    "        \n",
    "        # ENTITY FINDER IN QUESTION\n",
    "        for words in tagged_sent:\n",
    "            if words[0] == \"₹\":\n",
    "                found_entity = token_root_dict[words[0].strip()]\n",
    "                break\n",
    "            if (words[1] == 'QF' or words[1] == 'WQ'):\n",
    "                qf_flag = 1\n",
    "            if words[1] == 'JJ' and qf_flag == 1:\n",
    "                got_adj = words[1]\n",
    "            if (words[1] == 'NN' or words[1] == 'NNP' or words[1] == 'NNS' or words[1] == 'NNPC' or words[1] == 'PRP') and qf_flag == 1:\n",
    "                found_entity = got_adj.strip() + \" \" + token_root_dict[words[0].strip()]\n",
    "                break\n",
    "        \n",
    "        sum = 0\n",
    "        entity_found_in_state = False\n",
    "        found_entity = found_entity.strip()\n",
    "                    \n",
    "        # if money\n",
    "        if found_entity in [\"पैसे\" ,\"पैसा\" ,\"रुपये\" , \"कीमत\", \"क़ीमत\", \"लागत\", \"रुपया\", \"मूल्य\"]:\n",
    "            found_entity = \"₹\"\n",
    "        if operation == '-':\n",
    "            is_first_state = 0\n",
    "            for state in all_states:\n",
    "                # object specific\n",
    "                state[2] = state[2].strip()\n",
    "                if state[2].endswith(found_entity):\n",
    "                    if is_first_state == 0:\n",
    "                        sum = sum + float(state[1])\n",
    "                        is_first_state = 1\n",
    "                        entity_found_in_state = True\n",
    "                    else:\n",
    "                        sum = sum - float(state[1])\n",
    "\n",
    "            # cant find object, assume object of first state is the one\n",
    "            if entity_found_in_state is False:\n",
    "                found_entity = token_root_dict[all_states[0][2].strip()]\n",
    "                is_first_state = 0\n",
    "                for state in all_states:\n",
    "                    state[2] = state[2].strip()\n",
    "                    if state[2].endswith(found_entity) or state[2].startswith(found_entity):\n",
    "                        if is_first_state == 0:\n",
    "                            sum = sum + float(state[1])\n",
    "                            is_first_state = 1\n",
    "                            entity_found_in_state = True\n",
    "                        else:\n",
    "                            sum = sum - float(state[1])\n",
    "            return sum\n",
    "        else:\n",
    "            sum = 0\n",
    "            for state in all_states:\n",
    "                # object specific\n",
    "                state[2] = state[2].strip()\n",
    "                if state[2].endswith(found_entity):\n",
    "                    sum = sum + float(state[1])\n",
    "                    entity_found_in_state = True\n",
    "            # cant find object, assume object of first item is the one\n",
    "            if entity_found_in_state is False:\n",
    "                found_entity = all_states[0][2]\n",
    "                for state in all_states:\n",
    "                    state[2] = state[2].strip()\n",
    "                    if state[2].endswith(found_entity) or state[2].startswith(found_entity):\n",
    "                        sum = sum + float(state[1])\n",
    "                        entity_found_in_state = True\n",
    "            return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa38000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(sep_sentence):\n",
    "    wp_tags = []\n",
    "    for j in sep_sentence:\n",
    "        wp_tags.append(tagger.tag(j))\n",
    "    return wp_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fabf73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_change(current_word, current_tag, next_word, next_tag, assign, last_seen_proper_noun):\n",
    "    if current_word[0].isnumeric() and current_tag != 'QC':\n",
    "        current_tag = 'QC'\n",
    "    if next_word[0].isnumeric() and next_tag != 'QC':\n",
    "        next_tag = 'QC'\n",
    "    if current_tag == 'PRP' and len(assign) != 0:\n",
    "        current_word = assign[len(assign) - 1][0]\n",
    "    elif current_tag == 'PRP' and last_seen_proper_noun:\n",
    "        current_word = last_seen_proper_noun\n",
    "    return current_word, current_tag, next_word, next_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce135c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wpes = []\n",
    "total = 0\n",
    "source_length = len(source)\n",
    "for i in range(source_length):\n",
    "    wpes.append(source[i])\n",
    "    total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2277b542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verbcat():\n",
    "    all_vc_data = pd.read_csv('./verb-cat-full/data/all-verb-cat-data.csv', delimiter='\\t')\n",
    "    dfresult = all_vc_data.dropna()\n",
    "    token_cat = dfresult[['Token', 'VerbCategory']]\n",
    "    token_cat = token_cat.drop_duplicates()\n",
    "    neg=list(token_cat.loc[token_cat['VerbCategory'] == '-', 'Token'])\n",
    "    transferp=list(token_cat.loc[token_cat['VerbCategory'] == 't+', 'Token'])\n",
    "    transfern=list(token_cat.loc[token_cat['VerbCategory'] == 't-', 'Token'])\n",
    "    return neg, transferp, transfern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4560c9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative, transferp, transfern = get_verbcat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca1fa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "negative, transferp, transfern = get_verbcat()\n",
    "wrong = []\n",
    "for wpi, wpe in enumerate(wpes):\n",
    "    sentences = tk.tokenize(wpe[0])\n",
    "    wp_tags = get_tags(sentences)\n",
    "    containers = []\n",
    "    values = []\n",
    "    entities = []\n",
    "    states = [] # Container, Value, Adjective, Object\n",
    "    is_transfer = False\n",
    "    change_default_op = False\n",
    "    subtract_from_total_given = False\n",
    "    found_comparison = False\n",
    "    rem_size = 0\n",
    "    last_seen_proper_noun = None\n",
    "    \n",
    "    for sentence_idx in range(len(sentences)):\n",
    "        current_sent = sentences[sentence_idx]\n",
    "        current_tagset = wp_tags[sentence_idx]\n",
    "        qty_found = False\n",
    "        entity_found = False\n",
    "        # Stores the adjective assosciated with entity\n",
    "        last_seen_attribute = \"\"\n",
    "        # Stores the required proper noun, which is the first to the right of QC\n",
    "        last_seen_proper_noun = \"\"\n",
    "        for word_idx in range(0, len(current_tagset) - 1):\n",
    "            current_word = current_sent[word_idx]\n",
    "            current_tag = current_tagset[word_idx][1]\n",
    "            next_word = current_sent[word_idx + 1]\n",
    "            next_tag = current_tagset[word_idx + 1][1]\n",
    "            \n",
    "            current_word, current_tag, next_word, next_tag = some_change(current_word, current_tag, next_word, next_tag, states, last_seen_proper_noun)\n",
    "            if (found_comparison and current_word==\"कम\") and len(states) > 0:\n",
    "                # pehle not in first sentence\n",
    "                change_default_op = True\n",
    "                subtract_from_total_given = True\n",
    "            elif current_word == \"तुलना\" or current_word == \"मुकाबले\":\n",
    "                found_comparison = True\n",
    "                \n",
    "            # Handles special case: Money\n",
    "            if current_word == \"₹\":\n",
    "                entities.append(\"₹\")\n",
    "                values.append(next_word)\n",
    "                concat_string = last_seen_attribute + \" \" + token_root_dict[current_word.strip()]\n",
    "                change_sign = False\n",
    "                for check in negative:                                  # check for negative verbs\n",
    "                    if check == current_sent[word_idx + 2]: # use verb association instead of this\n",
    "                        change_sign = True\n",
    "                        break\n",
    "                if change_sign:\n",
    "                    values[len(values) -\n",
    "                           1] = float(values[len(values) - 1]) * (-1)\n",
    "                state = [last_seen_proper_noun, values[len(values) - 1], concat_string]\n",
    "                states.append(state)\n",
    "                last_seen_attribute = \"\"\n",
    "                qty_found = False\n",
    "                entity_found = False\n",
    "                continue\n",
    "            # in case an adjective is there\n",
    "            if current_tag == 'JJ' and (next_tag == 'NN' or next_tag == 'NNS' or next_tag == 'NNP') and qty_found:\n",
    "                last_seen_attribute = current_word\n",
    "                continue\n",
    "            if current_tag == 'QC':\n",
    "                if current_word[0].isnumeric():\n",
    "                    values.append(current_word)\n",
    "                    qty_found = True\n",
    "                    # getting the container\n",
    "                    containers.append(last_seen_proper_noun)\n",
    "            elif (current_tag == 'NN' or current_tag == 'NNS' or current_tag == 'NNP') and qty_found:\n",
    "                if (next_word == 'में' or next_word==\"पर\") and next_tag==\"PSP\"and qty_found==1:\n",
    "                    qty_found = False\n",
    "                    last_seen_proper_noun = current_word\n",
    "                    continue\n",
    "                entity_found = True\n",
    "                current_word = check_money(current_word)\n",
    "                concat_string = last_seen_attribute + \" \" + token_root_dict[current_word.strip()]\n",
    "                entities.append(concat_string)\n",
    "                change_sign = False\n",
    "                # what is the need of the following\n",
    "                if next_tag == 'VM' or next_word == 'नहीं' or next_word in negative:\n",
    "                    for check in negative:\n",
    "                        if check == next_word:\n",
    "                            change_sign = True\n",
    "                            break\n",
    "                if change_sign:\n",
    "                    values[len(values) -\n",
    "                           1] = float(values[len(values) - 1]) * (-1)\n",
    "                # storing the final instance as [ container name, value, object ]\n",
    "                state = [last_seen_proper_noun, values[len(values) - 1], concat_string]\n",
    "                states.append(state)\n",
    "                last_seen_attribute = \"\"\n",
    "                qty_found = False\n",
    "            elif current_tag == 'NNP' or current_tag == 'NNPC' or current_tag == 'PRP':\n",
    "                # stores the last proper noun before the quantifier\n",
    "                last_seen_proper_noun = current_word\n",
    "            elif current_tag == 'VM':\n",
    "                if entity_found==False and qty_found==True and len(states)>0:\n",
    "                    entity_found = True\n",
    "                    current_word = check_money(current_word)\n",
    "                    concat_string = last_seen_attribute + \" \" + states[len(states)-1][2].strip()\n",
    "                    entities.append(concat_string)\n",
    "                    change_sign = False\n",
    "                    # what is the need of the following\n",
    "                    if current_word in negative:\n",
    "                        for check in negative:\n",
    "                            if check == next_word:\n",
    "                                change_sign = True\n",
    "                                break\n",
    "                    if change_sign:\n",
    "                        values[len(values) -\n",
    "                               1] = float(values[len(values) - 1]) * (-1)\n",
    "                    # storing the final instance as [ container name, value, object ]\n",
    "                    state = [last_seen_proper_noun, values[len(values) - 1], concat_string]\n",
    "                    states.append(state)\n",
    "                    last_seen_attribute = \"\"\n",
    "                    qty_found = False\n",
    "                # check for transfer\n",
    "                kartas = kartafunc(current_sent, transferp, transfern, states, sentence_idx)\n",
    "                if kartas[0] != 0 and kartas[1] != 0 and kartas[2] != 0 and kartas[3]!='0':\n",
    "                    is_transfer = True\n",
    "                    temp = []\n",
    "                    for index2 in range(0, len(states) - 1):\n",
    "                        temp.append(states[index2])\n",
    "                    if len(values) > 0:\n",
    "                        states = update_state(\n",
    "                        kartas[0], kartas[1], kartas[3], values[len(values) - 1], kartas[2], temp)\n",
    "\n",
    "                # check for final sentence\n",
    "        if sentence_idx == len(sentences) - 1:\n",
    "            if len(states) != rem_size and subtract_from_total_given:\n",
    "                change_default_op = True\n",
    "            try:\n",
    "                store_ans = abs(finalsent(current_sent, states,\n",
    "                                  is_transfer, change_default_op))\n",
    "            except:\n",
    "                store_ans = -10000000\n",
    "            actual_ans = float(wpe[1])\n",
    "            pr = 0.01\n",
    "            diff = abs(actual_ans - store_ans)\n",
    "            if diff <= pr:\n",
    "                correct += 1\n",
    "            else:\n",
    "                wrong.append((wp_tags, states, actual_ans, store_ans))\n",
    "\n",
    "print(total)\n",
    "print(correct)\n",
    "acc = (correct) / (total)\n",
    "print(\"ACCURACY \")\n",
    "print(acc * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9966e699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf51cc4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf5a566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
